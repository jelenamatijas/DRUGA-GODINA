{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e301104-2e44-4682-b4a6-75ff5df1c7d0",
   "metadata": {},
   "source": [
    "# Zadaca 2: Stabla odlučivanja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c4ac2-93dc-4e7d-b467-35bcb20f2353",
   "metadata": {},
   "source": [
    "## Zadatak 1: Modifikacija stabla odlučivanja\n",
    "\n",
    "Modifikovati postojeću implementaciju algoritma tako da se dodaju sljedeće stavke:\n",
    "- radukovani kandidatski splitovi\n",
    "- random subspace sampling\n",
    "- opcioni cost-complexity prunning\n",
    "\n",
    "Potrebno je omogućiti da upotreba dodatnih stavki bude opciona, kroz proslijeđivanje odgovarajućih vrijednosti u konstruktor. Testirati brzinu i F1 metriiku rada klasifikatora na proizvoljnom skupu podataka, sa različitim kombinacijama novih opcija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a5224f-330f-44ee-a403-b08c39c9aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=5,\n",
    "        min_size=10,\n",
    "        max_features=None,\n",
    "        n_candidate_splits=None,\n",
    "        cost_complexity_pruning=False\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.max_features = max_features\n",
    "        self.n_candidate_splits = n_candidate_splits\n",
    "        self.cost_complexity_pruning = cost_complexity_pruning\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        dataset = [list(row) + [label] for row, label in zip(X, y)]\n",
    "        self.root = self._build_tree(dataset, depth=1)\n",
    "        if self.cost_complexity_pruning:\n",
    "            self.root = self._prune_cost_complexity(self.root, dataset)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_row(self.root, list(row)) for row in X]\n",
    "\n",
    "    def _build_tree(self, train, depth):\n",
    "        node = self._get_best_split(train)\n",
    "        if node['index'] is None:\n",
    "            return self._to_terminal(train)\n",
    "        self._split(node, depth)\n",
    "        return node\n",
    "\n",
    "    def _get_best_split(self, dataset):\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        features = self._select_features(len(dataset[0]) - 1)\n",
    "        best = {'index': None, 'value': None, 'score': float('inf'), 'groups': None}\n",
    "        for index in features:\n",
    "            candidates = self._generate_split_candidates(dataset, index)\n",
    "            for value in candidates:\n",
    "                groups = self._test_split(index, value, dataset)\n",
    "                gini = self._gini_index(groups, class_values)\n",
    "                if gini < best['score']:\n",
    "                    best.update({'index': index, 'value': value, 'score': gini, 'groups': groups})\n",
    "        return {'index': best['index'], 'value': best['value'], 'groups': best['groups']}\n",
    "\n",
    "    def _select_features(self, n_features):\n",
    "        features = list(range(n_features))\n",
    "        if self.max_features is not None and self.max_features < n_features:\n",
    "            features = random.sample(features, self.max_features)\n",
    "        return features\n",
    "\n",
    "    def _generate_split_candidates(self, dataset, index):\n",
    "        values = [row[index] for row in dataset]\n",
    "        unique_vals = sorted(set(values))\n",
    "        if self.n_candidate_splits and self.n_candidate_splits < len(unique_vals):\n",
    "            return list(np.linspace(min(values), max(values), self.n_candidate_splits))\n",
    "        return unique_vals\n",
    "\n",
    "    def _split(self, node, depth):\n",
    "        left, right = node['groups']\n",
    "        del node['groups']\n",
    "        if not left or not right:\n",
    "            terminal = self._to_terminal(left + right)\n",
    "            node['left'] = node['right'] = terminal\n",
    "            return\n",
    "\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'], node['right'] = self._to_terminal(left), self._to_terminal(right)\n",
    "            return\n",
    "\n",
    "        if len(left) <= self.min_size:\n",
    "            node['left'] = self._to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self._build_tree(left, depth + 1)\n",
    "        if len(right) <= self.min_size:\n",
    "            node['right'] = self._to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self._build_tree(right, depth + 1)\n",
    "\n",
    "    def _test_split(self, index, value, dataset):\n",
    "        left, right = [], []\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "\n",
    "    def _gini_index(self, groups, class_values):\n",
    "        n_instances = float(sum(len(g) for g in groups))\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in class_values:\n",
    "                p = [r[-1] for r in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "\n",
    "    def _to_terminal(self, group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "    def _predict_row(self, node, row):\n",
    "        if isinstance(node, dict):\n",
    "            if row[node['index']] < node['value']:\n",
    "                return self._predict_row(node['left'], row)\n",
    "            return self._predict_row(node['right'], row)\n",
    "        return node\n",
    "\n",
    "    def _prune_cost_complexity(self, node, dataset):\n",
    "        if not isinstance(node, dict):\n",
    "            return node\n",
    "\n",
    "        left_data, right_data = self._test_split(node['index'], node['value'], dataset)\n",
    "        node['left'] = self._prune_cost_complexity(node['left'], left_data)\n",
    "        node['right'] = self._prune_cost_complexity(node['right'], right_data)\n",
    "\n",
    "        if not isinstance(node['left'], dict) and not isinstance(node['right'], dict):\n",
    "            class_vals = list(set(r[-1] for r in dataset))\n",
    "            pre_gini = self._gini_index([left_data, right_data], class_vals)\n",
    "            merged_gini = self._gini_index([dataset], class_vals)\n",
    "            if merged_gini <= pre_gini:\n",
    "                return self._to_terminal(dataset)\n",
    "        return node\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
